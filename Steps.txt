############ Install JDK8 ########################
sudo apt update
sudo apt install openjdk-8-jdk
sudo update-alternatives --config java
export JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64/"
############ Install Maven #######################
sudo apt update
sudo apt install maven
############ Building Docker #####################
mvn clean package
docker build -t pm25-spring-boot-app .
docker images
docker run -p 8080:8080 pm25-spring-boot-app
############ Create Kubernetes Deployment ie. deployment.yaml ########
---
apiVersion: v1
kind: Service
metadata:
  name: pm25-svc
spec:
  selector:
    app: pm25-spring-boot-app

  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  type: NodePort

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata: {name: pm25-spring-boot-app}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pm25-spring-boot-app
      track: stable
  strategy:
    rollingUpdate: {maxSurge: 1, maxUnavailable: 0}
    type: RollingUpdate
  revisionHistoryLimit: 1
  template:
    metadata:
      labels:
        app: pm25-spring-boot-app
        track: stable
      name: pm25-spring-boot-app
    spec:
      containers:
      - name: pm26
        image: childzu/myrepo:pm25
        ports:
        - containerPort: 8080
      imagePullSecrets:
        - name: pm26registrykey
        resources:
          limits:
            memory: 0.25G
            cpu: 0.25
        terminationMessagePath: /dev/termination-log
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext: {}
      terminationGracePeriodSeconds: 30
############ Register docker to registry ##########
export REGISTRY=2886795353-5000-ollie02.environments.katacoda.com
docker tag pm25-spring-boot-app:<version> $REGISTRY/pm25-spring-boot-app:<version>
docker tag pm25-spring-boot-app pm25-spring-boot-app
docker push $REGISTRY/pm25-spring-boot-app:<version>
docker push pm25-spring-boot-app
sed -i -e 's@IMAGE_URL@'"$REGISTRY/pm25-spring-boot-app:<version>"'@' deployment.yaml
scp -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@host01:/root/.kube/config ~/.kube/
############ Run Kubernetes #######################
kubectl apply -f deployment.yaml
kubectl get services
kubectl get pods
kubectl get svc
kubectl get deployments
export PORT=$(kubectl get svc pm25-spring-boot-app -o go-template='{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{"\n"}}{{end}}{{end}}')
curl host01:$PORT 
########### Create Registry Key ###################
kubectl create secret docker-registry pm26registrykey --docker-server=https://index.docker.io/v1/ --docker-username=childzu --docker-password=<password> --docker-email=childzu@gmail.com
kubectl get secret pm26registrykey --output="jsonpath={.data.\.dockerconfigjson}" | base64 --decode

########### Networking ############################
#1. Cluster TP 
It can be done by set replicas > 1 in deployments file.
Example
---
apiVersion: v1
kind: Service
metadata:
  name: webapp1-clusterip-svc
  labels:
    app: webapp1-clusterip
spec:
  ports:
  - port: 80
  selector:
    app: webapp1-clusterip
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp1-clusterip-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp1-clusterip
    spec:
      containers:
      - name: webapp1-clusterip-pod
        image: katacoda/docker-http-server:latest
        ports:
        - containerPort: 80
---
export CLUSTER_IP=$(kubectl get services/<service-name> -o go-template='{{(index .spec.clusterIP)}}')
curl $CLUSTER_IP:80
#2. Target Port
It can be done by set Target Port on service deploment file
Example 
apiVersion: v1
kind: Service
metadata:
  name: webapp1-clusterip-targetport-svc
  labels:
    app: webapp1-clusterip-targetport
spec:
  ports:
  - port: 8080
    targetPort: 80
  selector:
    app: webapp1-clusterip-targetport
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp1-clusterip-targetport-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp1-clusterip-targetport
    spec:
      containers:
      - name: webapp1-clusterip-targetport-pod
        image: katacoda/docker-http-server:latest
        ports:
        - containerPort: 80
---
export CLUSTER_IP=$(kubectl get services/webapp1-clusterip-targetport-svc -o go-template='{{(index .spec.clusterIP)}}')
curl $CLUSTER_IP:8080
#3. NodePort
NodePort exposes the service on each Nodeâ€™s IP via the defined static port
We can access service on Node's IP address
It can be done by setting NodePort in service deployment file
Example
---
apiVersion: v1
kind: Service
metadata:
  name: webapp1-nodeport-svc
  labels:
    app: webapp1-nodeport
spec:
  type: NodePort
  ports:
  - port: 80
    nodePort: 30080
  selector:
    app: webapp1-nodeport
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp1-nodeport-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp1-nodeport
    spec:
      containers:
      - name: webapp1-nodeport-pod
        image: katacoda/docker-http-server:latest
        ports:
        - containerPort: 80
---
Check node's IP is below
kubectl get nodes -o wide
NAME      STATUS    ROLES     AGE       VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
master    Ready     master    35m       v1.11.3   172.17.0.7    <none>        Ubuntu 16.04.2 LTS   4.4.0-62-generic   docker://1.13.1
curl 172.17.0.7:30080

#4. External IPs
We can access service of pod by making a service available outside of the cluster is via External IP addresses.
It can be done by setting externalIPs: in the service deployment file.
Example
---
apiVersion: v1
kind: Service
metadata:
  name: webapp1-externalip-svc
  labels:
    app: webapp1-externalip
spec:
  ports:
  - port: 80
  externalIPs:
  - 172.17.0.7
  selector:
    app: webapp1-externalip
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp1-externalip-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp1-externalip
    spec:
      containers:
      - name: webapp1-externalip-pod
        image: katacoda/docker-http-server:latest
        ports:
        - containerPort: 80
---
In the above service config external IPs with 172.17.0.7 and Port is 80 then
we can access the service like below
curl 172.17.0.7

#5. Load Balancer
We can define our service to load balance by using capability of Cloud Provider Load Balancer
It can be done by setting type: LoadBalancer in service deployment file
Example
---
apiVersion: v1
kind: Service
metadata:
  name: webapp1-loadbalancer-svc
  labels:
    app: webapp1-loadbalancer
spec:
  type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: webapp1-loadbalancer
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: webapp1-loadbalancer-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: webapp1-loadbalancer
    spec:
      containers:
      - name: webapp1-loadbalancer-pod
        image: katacoda/docker-http-server:latest
        ports:
        - containerPort: 80
---
Get LoadBalancerIP like below
export LoadBalancerIP=$(kubectl get services/webapp1-loadbalancer-svc -o go-template='{{(index .status.loadBalancer.ingress 0).ip}}')
echo LoadBalancerIP=$LoadBalancerIP
LoadBalancerIP=10.10.0.1
curl $LoadBalancerIP

################ Ingress ####################
#0 Deploy Our Application 
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: pm25-dep
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: pm25
    spec:
      containers:
      - name: pm25
        image: childzu/myrepo:pm25
        ports:
        - containerPort: 8080

---
apiVersion: v1
kind: Service
metadata:
  name: pm25-svc
  labels:
    app: pm25
spec:
  ports:
  - port: 8080
  selector:
    app: pm25
 
# 1. default-backend-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: default-backend
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: default-backend
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: default-backend
        image: gcr.io/google_containers/defaultbackend:1.0
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 30
          timeoutSeconds: 5
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: 10m
            memory: 20Mi
          requests:
            cpu: 10m
            memory: 20Mi

#2 default-backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: default-backend
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app: default-backend
    
 $ create -f default-backend-deployment.yaml -f default-backend-service.yaml -n=ingress

#3 nginx-ingress-controller-config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-ingress-controller-conf
  labels:
    app: nginx-ingress-lb
data:
  enable-vts-status: 'true'


$ kubectl create -f nginx-ingress-controller-config-map.yaml -n=ingress

#4 nginx-ingress-controller-roles.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-role
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - endpoints
  - nodes
  - pods
  - secrets
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - update
  - watch
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - extensions
  resources:
  - ingresses/status
  verbs:
  - update
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nginx-role
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nginx-role
subjects:
- kind: ServiceAccount
  name: nginx
  namespace: ingress

$ kubectl create -f nginx-ingress-controller-roles.yaml -n=ingress

#5 nginx-ingress-controller-deployment.yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-ingress-controller
spec:
  replicas: 1
  revisionHistoryLimit: 3
  template:
    metadata:
      labels:
        app: nginx-ingress-lb
    spec:
      terminationGracePeriodSeconds: 60
      serviceAccount: nginx
      containers:
        - name: nginx-ingress-controller
          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.9.0
          imagePullPolicy: Always
          readinessProbe:
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
          livenessProbe:
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            timeoutSeconds: 5
          args:
            - /nginx-ingress-controller
            - --default-backend-service=\$(POD_NAMESPACE)/default-backend
            - --configmap=\$(POD_NAMESPACE)/nginx-ingress-controller-conf
            - --v=2
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 80
            - containerPort: 18080

$ kubectl create -f nginx-ingress-controller-deployment.yaml -n=ingress
$ kubectl get pods -n ingress

#6 Create Ingress Rules for Applications
nginx-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx-ingress
spec:
  rules:
  - host: test.akomljen.com
    http:
      paths:
      - backend:
          serviceName: nginx-ingress
          servicePort: 18080
        path: /nginx_status
        
# 7 app-ingress.yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  name: app-ingress
spec:
  rules:
  - host: test.pm25.com
    http:
      paths:
      - backend:
          serviceName: pm25-svc
          servicePort: 8080
        path: /app1
      - backend:
          serviceName: pm25-svc
          servicePort: 8080
        path: /app2

$ kubectl create -f nginx-ingress.yaml -n=ingress
$ kubectl create -f app-ingress.yaml

#10 Expose Nginx Ingress Controller
nginx-ingress-controller-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress
spec:
  type: NodePort
  ports:
    - port: 80
      nodePort: 30000
      name: http
    - port: 18080
      nodePort: 32000
      name: http-mgmt
  selector:
    app: nginx-ingress-lb

$ kubectl create -f nginx-ingress-controller-service.yaml -n=ingress

#11 If neccessary 
#Add dns name
echo "127.0.0.1 test.akomljen.com" | sudo tee -a /etc/hosts
#Forward port 
kubectl port-forward svc/nginx-ingress -n ingress 80:80

#12 Testing !!!!!!!!!!!!
curl http://test.pm25.com/app1
curl http://test.pm25.com/app2
curl -H "Host: test.pm25.com" test.pm25.com/app1/api/weather/60t
curl -H "Host: test.pm25.com" test.pm25.com/app2/api/weather/60t